<!DOCTYPE html>
<!-- saved from url=(0057)http://www.icst.pku.edu.cn/struct/people/yangs/index.html -->
<html class="csstransforms csstransforms3d csstransitions"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		
		<title>Huafeng Li</title>
		<link href="./files/bootstrap.css" rel="stylesheet" type="text/css" media="all">
		<link href="./files/style.css" rel="stylesheet" type="text/css" media="all">
		<link href="./files/prettyPhoto.css" rel="stylesheet" type="text/css" media="all">		
		<link href="./files/css" rel="stylesheet" type="text/css">	
	</head>
	<body>
		<!---start-wrap--->
		<!---start-header--->
	<div class="header">
		<div class="wrap">
			<!---start-logo--->
			<div class="logo">
				<a href="./index.html">Huafeng Li</a>
			</div>
			<!---End-logo--->
			<!---start-top-nav--->
			<div class="top-nav">
				<ul>
					<li id="Home" onclick="func(&#39;Me&#39;)"><a href="./index.html" class="scroll">Home</a></li>
					<li id="Profile" onclick="func(&#39;Profile&#39;)"><a href="./Profile.html" class="scroll">Profile</a></li>
					<li id="Publications" onclick="func(&#39;Publications&#39;)"><a href="./Publication.html" class="scroll">Publications</a></li>
					<!--<li id="Profile-chinese" onclick="func(&#39;Honors Awards&#39;)"><a href="./Honors Awards.html" class="scroll">Honors & Awards</a></li>-->
					<li id="MVPLab" onclick="func(&#39;MVP Lab&#39;)"><a href="./MVPLab.html" class="scroll">VIP Group</a></li>
                                        <!--<li id="Projects" onclick="func(&#39;Projects&#39;)"><a href="./Project.html" class="scroll">Projects</a></li>-->
					<!-- <li id="Art" onclick="func(&#39;Art&#39;)"><a href="http://www.icst.pku.edu.cn/struct/people/yangs/index.html#art" class="scroll">Art Gallery</a></li>	-->
					<li id="Profile-chinese" onclick="func(&#39;Profile-chinese&#39;)"><a href="./Profile-chinese.html" class="scroll">中文简介</a></li>
					<li id="Contact" onclick="func(&#39;Contact&#39;)"><a href="./Contact.html" class="scroll">Contact</a></li>
				</ul>
			</div>
			<div class="clear"> </div>
			<!---End-top-nav--->
	     </div>
	</div>
	
	<script> 
	var lastname = 'Me';
	function func(name){
		var div = document.getElementById(name); 
		div.className = 'active'; 
		div = document.getElementById(lastname); 
		div.className = ''; 
		lastname = name;
	}
	function coming_soon()
	{
		alert("Coming soon.");
	}
	</script> 
	
		<!---End-wrap--->
	<div class="content">
		<div class="grid3">
			<div class="grid3-content">
		<h3><b>Selected Publications and Patents:</b></h3>
	
                

	
	<!--COPYRIGHT: The copyright of the following materials belongs to corresponding publishers. 
They are provided only for research and educational use that does not conflict to the interests of the publishers.
-->
	  </ul>
  <hr />			
<!-- 			
<h4><b>Pre-print:</b></h4>
<ul class="graid3-ul">
<div style="text-align: justify; display: block; margin-right: auto;">
				

  </ul>
  <hr />-->
				

	<hr />	


				
<h4><b>2024:</b></h4>
		<ul class="graid3-ul">
  <div style="text-align: justify; display: block; margin-right: auto;">	
<li>Y. Zhang, Z. Li, H. Li and D. Tao, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10755138" target="_blank"><font color="#0000FF">"Prototype-Driven and Multi-Expert Integrated Multi-Modal MR Brain Tumor Image Segmentation"</font></a>, 
  <ud2>IEEE Transactions on Instrumentation and Measurement</ud2>, doi: 10.1109/TIM.2024.3500067.  
  <a href="https://github.com/Linzy0227/PDMINet." target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Huafeng and Fang, Jiaqi and Zhang, Yafei and Liu, Yu, 
  <a href="https://arxiv.org/abs/2411.12586" target="_blank"><font color="#0000FF">Infrared-Assisted Single-Stage Framework for Joint Restoration and Fusion of Visible and Infrared Images under Hazy Conditions</font></a>, 
  <ud2>arXiv preprint</ud2>, 2024.
</li>

<li>Yang, Zengyi and Zhang, Yafei and Li, Huafeng and Liu, Yu, 
  <a href="https://arxiv.org/abs/2411.09387" target="_blank"><font color="#0000FF">Instruction-Driven Fusion of Infrared-Visible Images: Tailoring for Diverse Downstream Tasks</font></a>, 
  <ud2>arXiv preprint</ud2>, 2024.
</li>

<li>Xie, Minghong and Wang, Mengzhao and Li, Huafeng and Zhang, Yafei and Tao, Dapeng and Yu, Zhengtao, 
  <a href="https://arxiv.org/abs/2410.23570" target="_blank"><font color="#0000FF">Phrase Decoupling Cross-Modal Hierarchical Matching and Progressive Position Correction for Visual Grounding</font></a>, 
  <ud2>arXiv preprint</ud2>, 2024.  
  <a href="https://github.com/X7J92/VGNet" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Fan and Zhou, Hang and Li, Huafeng and Zhang, Yafei and Yu, Zhengtao, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10701572" target="_blank"><font color="#0000FF">Person text-image matching via text-feature interpretability embedding and external attack node implantation</font></a>, 
  <ud2>IEEE Transactions on Emerging Topics in Computational Intelligence</ud2>, 2024.  
  <a href="https://github.com/lhf12278/SAA" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Huafeng and Zhang, Chen and Hu, Zhanxuan and Zhang, Yafei and Yu, Zhengtao, 
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608024002739" target="_blank"><font color="#0000FF">Interactive attack-defense for generalized person re-identification</font></a>, 
  <ud2>Neural Networks</ud2>, vol. 176, pp. 106349, 2024.  
  <a href="https://github.com/lhf12278/IAD." target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Zhang, Fan and Liu, Huiying and Wang, Jinjiang and Lyu, Jun and Cai, Qing and Li, Huafeng and Dong, Junyu and Zhang, David, 
  <a href="https://www.sciencedirect.com/science/article/pii/S0031320324001778" target="_blank"><font color="#0000FF">Cross co-teaching for semi-supervised medical image segmentation</font></a>, 
  <ud2>Pattern Recognition</ud2>, vol. 152, pp. 110426, 2024.  
  <a href="https://github.com/Fan-NWPU/CroCT" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Yu, Xiaoyan and Zhou, Shen and Li, Huafeng and Zhu, Liehuang, 
  <a href="https://arxiv.org/abs/2407.19139" target="_blank"><font color="#0000FF">Multi-Expert Adaptive Selection: Task-Balancing for All-in-One Image Restoration</font></a>, 
  <ud2>arXiv preprint</ud2>, 2024.  
  <a href="https://github.com/zhoushen1/MEASNet" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Xu, Kaixiong and Li, Huafeng and Chai, Yi and Guo, Maoyun, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10601528" target="_blank"><font color="#0000FF">Feature Adaptive Modulation and Prototype Learning for Domain Generalization Intelligent Fault Diagnosis</font></a>, 
  <ud2>IEEE Transactions on Industrial Informatics</ud2>, 2024.
</li>
<li>Hu, Qingsong and Li, Huafeng and Hu, Zhanxuan and Nie, Feiping, 
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253524000976" target="_blank"><font color="#0000FF">Diverse semantic information fusion for Unsupervised Person Re-Identification</font></a>, 
  <ud2>Information Fusion</ud2>, vol. 107, pp. 102319, 2024.  
  <a href="https://github.com/qingsonghu08/FuseDSI" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Gao, Yu and Zheng, Xutao and Li, Jinxing and Zong, Lijun and Yin, Hongpeng and Li, Huafeng and Lu, Guangming, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10531759/" target="_blank"><font color="#0000FF">Disentanglement Learning With Adaptive Centroid Alignment for Multiple Target Domains Fault Diagnosis</font></a>, 
  <ud2>IEEE Transactions on Industrial Informatics</ud2>, 2024.
</li>

<li>Zhang, Fan and Liu, Huiying and Duan, Xiaojun and Wang, Binglu and Cai, Qing and Li, Huafeng and Dong, Junyu and Zhang, David, 
  <a href="https://www.sciencedirect.com/science/article/pii/S0957417423032748" target="_blank"><font color="#0000FF">DSLSM: Dual-kernel-induced statistic level set model for image segmentation</font></a>, 
  <ud2>Expert Systems with Applications</ud2>, vol. 242, pp. 122772, 2024.
</li>

<li>Li, Zhiyuan and Zhang, Yafei and Li, Huafeng and Chai, Yi and Yang, Yushi, 
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1746809424000703" target="_blank"><font color="#0000FF">Deformation-aware and reconstruction-driven multimodal representation learning for brain tumor segmentation with missing modalities</font></a>, 
  <ud2>Biomedical Signal Processing and Control</ud2>, vol. 91, pp. 106012, 2024.  
  <a href="https://github.com/Linzy0227/SRMNet" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Huafeng and Liu, Junyu and Zhang, Yafei and Liu, Yu, 
  <a href="https://link.springer.com/article/10.1007/s11263-023-01948-x" target="_blank"><font color="#0000FF">A deep learning framework for infrared and visible image fusion without strict registration</font></a>, 
  <ud2>International Journal of Computer Vision</ud2>, vol. 132, no. 5, pp. 1625–1644, 2024.
</li>

<li>Li, Huafeng and Yang, Zhenmei and Zhang, Yafei and Tao, Dapeng and Yu, Zhengtao, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10465638" target="_blank"><font color="#0000FF">Single-Image HDR Reconstruction Assisted Ghost Suppression and Detail Preservation Network for Multi-Exposure HDR Imaging</font></a>, 
  <ud2>IEEE Transactions on Computational Imaging</ud2>, 2024.  
  <a href="https://github.com/lhf12278/SAMHDR" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Huafeng and Yuan, Ming and Li, Jinxing and Liu, Yu and Lu, Guangming and Xu, Yong and Yu, Zhengtao and Zhang, David, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10461111" target="_blank"><font color="#0000FF">Focus Affinity Perception and Super-Resolution Embedding for Multifocus Image Fusion</font></a>, 
  <ud2>IEEE Transactions on Neural Networks and Learning Systems</ud2>, 2024.
</li>

<li>Li, Huafeng and Hu, Qingsong and Hu, Zhanxuan, 
  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28092" target="_blank"><font color="#0000FF">Catalyst for Clustering-Based Unsupervised Object Re-identification: Feature Calibration</font></a>, 
  <ud2>Proceedings of the AAAI Conference on Artificial Intelligence</ud2>, vol. 38, no. 4, pp. 3091–3099, 2024.  
  <a href="https://github.com/lhf12278/FCM-ReID" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Zhang, Yafei and Yang, Xuji and Li, Huafeng and Xie, Minghong and Yu, Zhengtao, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10473165" target="_blank"><font color="#0000FF">DCPNet: A Dual-Task Collaborative Promotion Network for Pansharpening</font></a>, 
  <ud2>IEEE Transactions on Geoscience and Remote Sensing</ud2>, vol. 62, pp. 1–16, 2024.
</li>

<li>Wang, Hongbin and Chen, Rui and Shu, Zhenqiu and Zhang, Yafei and Li, Huafeng, 
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231223012365" target="_blank"><font color="#0000FF">Supervised adaptive similarity consistent latent representation hashing</font></a>, 
  <ud2>Neurocomputing</ud2>, vol. 570, pp. 127113, 2024.
</li>
<li>Li, Rui and Liu, Yishu and Li, Huafeng and Li, Jinxing and Lu, Guangming, 
  <a href="https://dl.acm.org/doi/abs/10.1145/3664647.3681211" target="_blank"><font color="#0000FF">Prototype-Guided Dual-Transformer Reasoning for Video Individual Counting</font></a>, 
  <ud2>Proceedings of the 32nd ACM International Conference on Multimedia</ud2>, pp. 10258–10267, 2024.
</li>

<li>万磊, 李华锋 and 张亚飞, 
  <a href="https://www.jcad.cn/cn/article/id/01ea269a-2c53-4c9e-8e24-dca9ce886115" target="_blank"><font color="#0000FF">多模态特征融合和自蒸馏的红外-可见光行人重识别</font></a>, 
  <ud2>计算机辅助设计与图形学学报</ud2>, 2024.
</li>

<li>毛彦嵋, 李华锋 and 张亚飞, 
  面向跨区域场景的无监督域自适应行人重识别 (网络首发), 
  <ud2>上海交通大学学报</ud2>, pp. 0, 2024.
</li>

<li>Zhang, Yafei and Zhou, Shen and Li, Huafeng, 
  <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Depth_Information_Assisted_Collaborative_Mutual_Promotion_Network_for_Single_Image_CVPR_2024_paper.html" target="_blank"><font color="#0000FF">Depth Information Assisted Collaborative Mutual Promotion Network for Single Image Dehazing</font></a>, 
  <ud2>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</ud2>, pp. 2846–2855, 2024.  
  <a href="https://github.com/zhoushen1/DCMPNet" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Chen, Liping and Xie, Siqiang and Lopes, António M and Li, Huafeng and Bao, Xinyuan and Zhang, Chaolong and Li, Penghua, 
  <a href="https://www.sciencedirect.com/science/article/pii/S0360544223029912" target="_blank"><font color="#0000FF">A new SOH estimation method for Lithium-ion batteries based on model-data-fusion</font></a>, 
  <ud2>Energy</ud2>, vol. 286, pp. 129597, 2024.
</li>
	  </ul>
  <hr />

				
<h4><b>2023:</b></h4>
		<ul class="graid3-ul">
  <div style="text-align: justify; display: block; margin-right: auto;">	



	  
	  </ul>
  <hr />
			
			
			
			
	
<h4><b>2022:</b></h4>
		<ul class="graid3-ul">
  <div style="text-align: justify; display: block; margin-right: auto;">
 
	
	 
	  </ul>
  <hr />
	
	
	
<h4><b>2021:</b></h4>
		<ul class="graid3-ul">
  <div style="text-align: justify; display: block; margin-right: auto;">
 
  
	  	  
	 
	  </ul>
  <hr />
	
	
<h4><b>2020:</b></h4>
		<ul class="graid3-ul">
<div style="text-align: justify; display: block; margin-right: auto;">  



  
	</ul>
			<hr />
				
<h4><b>2019:</b></h4>
<ul class="graid3-ul">
  <div style="text-align: justify; display: block; margin-right: auto;">

 	  
	  
	  
</ul>
	<hr />
  
<h4><b>2018:</b></h4>
		<ul class="graid3-ul">
  <div style="text-align: justify; display: block; margin-right: auto;">


  </ul>
  <hr />
			
<h4><b>2017:</b></h4>
		<ul class="graid3-ul">
<div style="text-align: justify; display: block; margin-right: auto;">  


  </ul>
			<hr />
			
<h4><b>2016:</b></h4>
		<ul class="graid3-ul">
<div style="text-align: justify; display: block; margin-right: auto;">
	

</ul>
			<hr />
<!--
<h4><b>2015:</b></h4>
		<ul class="graid3-ul">
 <div style="text-align: justify; display: block; margin-right: auto;">
	 
<li> Ping Han, <strong>Runmin Cong</strong>, and Zaiji Zhang, 
  <font color="#0000FF">Change detection algorithm of polarimetric SAR image based on polarization state extracting</font>,
  <ud2>Systems Engineering and Electronics</ud2>, vol. 37, no. 7, pp. 1526-1530, 2015. (in Chinese, EI)<br></li>
  </ul>
				<hr />
-->
			
<h4><b>授权中国发明专利:</b></h4>
<ul class="graid3-ul">
<div style="text-align: justify; display: block; margin-right: auto;">
	 
<li>一种立体视觉显著性检测方法，专利号：ZL 201610244589.9，申请日：2016.04.19，授权公告日：2018.08.31</li>
<li>一种RGB-D图像显著性目标检测方法，专利号：ZL 202110872457.1，申请日：2021.07.30，授权公告日：2023.07.28</li>
<li>一种RGB-D图像显著性目标检测方法，专利号：ZL 202010199264.X，申请日：2020.03.20，授权公告日：2023.08.30</li>
<li>一种图间显著性检测方法，专利号：ZL 201710942099.0，申请日：2017.10.11，授权公告日：2021.04.16</li>
<li>一种深度图可靠性评价测度方法，专利号：ZL 201610242241.6，申请日：2016.04.19，授权公告日：2018.08.10</li>	 
<li>一种迭代协同显著性检测方法，专利号：ZL 201711064083.0，申请日：2017.11.02，授权公告日：2021.06.04</li>
<li>一种协同显著性检测方法，专利号：ZL 201710942783.9，申请日：2017.10.11，授权公告日：2021.06.04</li>
<li>一种深度形状先验提取方法，专利号：ZL 201711065005.2，申请日：2017.11.02，授权公告日：2021.04.30</li>
<li>一种 RGBD 图像协同显著性检测方法，专利号：ZL 201810879724.6，申请日：2018.08.03，授权公告日：2021.09.17</li>
<li>一种RGB显著性到RGBD显著性的转换方法，专利号：ZL 201910375809.5，申请日：2019.05.07，授权公告日：2023.04.18</li>	
<li>一种视频显著性检测方法，专利号：ZL 201910266112.4，申请日：2019.04.03，授权公告日：2023.02.07</li>	
<li>一种立体图像重定向方法，专利号：ZL 201610874827.4，申请日：2016.09.30，授权公告日：2019.12.06</li>
<li>一种深度视频快速帧内编码方法，专利号：ZL 201810317701.6，申请日：2018.04.10，授权公告日：2021.04.30</li>
<li>一种联合场景和运动多特征的视频行为聚类方法，专利号：ZL 201810962264.3，申请日：2018.08.22，授权公告日：2021.06.04</li>
<li>深度图超分辨率重建方法，专利号：ZL 201610727602.6，申请日：2016.08.25，授权公告日：2019.10.18</li>	
<li>一种2D转3D深度估计方法，专利号：ZL 201610780883.1，申请日：2016.08.31，授权公告日：2019.06.04</li>	 	 
<li>一种立体图像匹配图计算方法，专利号：ZL 201610780786.2，申请日：2016.08.31，授权公告日：2019.05.31</li>	
<li>一种基于最优化颜色修正和回归模型的水下图像复原方法，专利号：ZL 201610606187.9，申请日：2016.07.25，授权公告日：2019.03.29</li>  
<li>一种屏幕内容与自然内容划分及快速编码方法，专利号：ZL 201611031480.3，申请日：2016.11.18，授权公告日：2019.01.29</li>
<li>一种基于虚拟视点绘制质量的深度图上采样方法，专利号：ZL 201610751851.9，申请日：2016.08.27，授权公告日：2019.08.02</li>	
<li>一种基于协同注意力的草图图像检索方法，专利号：ZL 201910746351.X，申请日：2019.08.13，授权公告日：2022.11.15</li>	
<li>一种基于半异构联合嵌入网络的草图图像检索方法，专利号：ZL 201910746354.3 申请日：2019.08.13，授权公告日：2022.12.02</li>	
	 
	<!-- 
<li><strong>丛润民</strong>，雷建军，侯春萍，李重仪，贺小旭，段金辉. 一种立体视觉显著性检测方法，专利号：ZL 201610244589.9，申请日：2016.04.20，授权公告日：2018.08.31
</li>

<li>雷建军，<strong>丛润民</strong>，侯春萍，段金辉，李东阳. 一种深度图可靠性评价测度，专利号：ZL 201610242241.6，申请日：2016.04.20，授权公告日：2018.08.10
 </li>	 

<li>雷建军，<strong>丛润民</strong>，侯春萍，张三义，陈越，郭琰. 一种迭代协同显著性检测方法，专利号：ZL 201711064083.0，申请日：2017.11.02，授权公告日：2021.06.04</li>
<li>雷建军，<strong>丛润民</strong>，侯春萍，张静，范晓婷，彭勃. 一种协同显著性检测方法，专利号：ZL 201710942783.9，申请日：2017.10.11，授权公告日：2021.06.04</li>
<li>雷建军，<strong>丛润民</strong>，侯春萍，李欣欣，韩梦芯，罗晓维. 一种深度形状先验提取方法，专利号：ZL 201711065005.2，申请日：2017.11.02，授权公告日：2021.04.30</li>
<li>雷建军，张凯明，孙振燕，彭勃，<strong>丛润民</strong>，张曼华，徐遥令. 一种深度视频快速帧内编码方法，专利号：ZL 201810317701.6，申请日：2018.04.10，授权公告日：2021.04.30</li>
<li>雷建军，彭勃，郑泽勋，贾亚龙，<strong>丛润民</strong>，张静. 一种联合场景和运动多特征的视频行为聚类方法，申请号：201810962264.3，申请日：2018.08.22，授权公告日：2021.06.04</li>


<li>郭继昌，李重仪，<strong>丛润民</strong>，郭春乐，顾翔元.一种基于最优化颜色修正和回归模型的水下图像复原方法，专利号：ZL 201610606187.9，申请日：2016.07.25，授权公告日：2019.03.29
 </li> 

<li>雷建军，吴敏，侯春萍，<strong>丛润民</strong>，李乐乐，郭琰. 一种立体图像重定向方法，专利号：ZL 201610874827.4，申请日：2016.09.30，授权公告日：2019.12.06
 </li>
	 
<li>雷建军，李乐乐，侯春萍，<strong>丛润民</strong>，张凝，吴敏. 一种基于虚拟视点绘制质量的深度图上采样方法，专利号：ZL 201610751851.9，申请日：2016.08.27，授权公告日：2019.08.02
 </li>	 
	 
<li>雷建军，李乐乐，侯春萍，吴敏，<strong>丛润民</strong>，倪敏. 深度图超分辨率重建方法，专利号：ZL 201610727602.6，申请日：2016.08.25，授权公告日：2019.10.18
</li>	
	 
<li>吴敏，雷建军，侯春萍，李乐乐，<strong>丛润民</strong>，梅旭光. 一种立体图像匹配图计算方法，专利号：ZL 201610780786.2，申请日：2016.08.31，授权公告日：2019.05.31
</li>	
	 
<li>雷建军，李东阳，侯春萍，孙振燕，<strong>丛润民</strong>，彭勃. 一种屏幕内容与自然内容划分及快速编码方法，专利号：ZL 201611031480.3，申请日：2016.11.18，授权公告日：2019.01.29
   </li>
	 
<li>雷建军，张凝，侯春萍，张翠翠，郑凯夫，<strong>丛润民</strong>. 一种2D转3D深度估计方法，专利号：ZL 201610780883.1，申请日：2016.08.31，授权公告日：2019.06.04
 </li>	 	 
	--> 
  </ul>	
	<hr />
			
<ul class="graid3-ul">
        <div style="text-align: justify; display: block; margin-right: auto;">
	Here are the Impact Factors (IF) of selected journals of my publications. <br>
        - IEEE Transactions on Cybernetics (TCyb): 19.118 <br>
	- IEEE Transactions on Neural Networks and Learning Systems (TNNLS): 14.255<br>
	- IEEE Transactions on Industrial Informatics (TII): 11.648<br>
	- IEEE Transactions on Image Processing (TIP): 11.041 <br>
	- IEEE Transactions on Intelligent Transportation Systems (TITS): 9.551  <br>
	- IEEE Transactions on Multimedia (TMM): 8.182 <br> 
	- IEEE Transactions on Geoscience and Remote Sensing (TGRS): 8.125 <br>
	- IEEE Transactions on Circuits and Systems for Video Technology (TCSVT): 5.859 <br>
	- IEEE Transactions on Automation Science and Engineering (TASE): 5.6 <br>
	- IEEE Transactions on Instrumentation and Measurement (TIM): 5.332 <br>
	- IEEE Transactions on Computational Imaging (TCI): 4.708 <br>
	- IEEE Transactions on Consumer Electronics (TCE): 4.414 <br>
	- IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI): 4.851 <br>
	- IEEE Journal of Biomedical and Health Informatics (JBHI): 7.021<br>
	- SCIENCE CHINA Information Sciences (SCIS): 7.275<br>
	- ACM Transactions on Multimedia Computing Communications and Applications (TOMM): 4.094<br>
	- Information Sciences: 8.233 <br>
	- Neurocomputing: 5.779 <br>
	- Pattern Recognition Letters (PRL): 4.757 <br>
	- IEEE Signal Processing Letters (SPL): 3.201 <br>
	- International Journal of Remote Sensing (IJRS): 3.531	 <br>
	- Signal Processing: Image Communication (SPIC): 3.453 <br>
	- Multimedia Tools and Applications (MTAP): 2.577 <br>
	- Journal of Electronic Imaging (JEI): 0.829<br>
	
	
			
			
	</div>			
		</div>	
	</div>
	
		<script type="text/javascript" src="./files/jquery.min.js.下载"></script>
		<script type="text/javascript" src="./files/bootstrap.js.下载"></script>
		<script type="text/javascript" src="./files/jquery.banner.js.下载"></script>
		<script type="text/javascript" src="./files/jquery.prettyPhoto.js.下载"></script>		
		<script type="text/javascript" src="./files/jquery.isotope.js.下载"></script>	
		<script type="text/javascript" src="./files/main.js.下载"></script>				
	


</body></html>
