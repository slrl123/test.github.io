<!DOCTYPE html>
<!-- saved from url=(0057)http://www.icst.pku.edu.cn/struct/people/yangs/index.html -->
<html class="csstransforms csstransforms3d csstransitions"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		
		<title>Huafeng Li</title>
		<link href="./files/bootstrap.css" rel="stylesheet" type="text/css" media="all">
		<link href="./files/style.css" rel="stylesheet" type="text/css" media="all">
		<link href="./files/prettyPhoto.css" rel="stylesheet" type="text/css" media="all">		
		<link href="./files/css" rel="stylesheet" type="text/css">	
	</head>
	<body>
		<!---start-wrap--->
		<!---start-header--->
	<div class="header">
		<div class="wrap">
			<!---start-logo--->
			<div class="logo">
				<a href="./index.html">Huafeng Li</a>
			</div>
			<!---End-logo--->
			<!---start-top-nav--->
			<div class="top-nav">
				<ul>
					<li id="Home" onclick="func(&#39;Me&#39;)"><a href="./index.html" class="scroll">Home</a></li>
					<li id="Profile" onclick="func(&#39;Profile&#39;)"><a href="./Profile.html" class="scroll">Profile</a></li>
					<li id="Publications" onclick="func(&#39;Publications&#39;)"><a href="./Publication.html" class="scroll">Publications</a></li>
					<!--<li id="Profile-chinese" onclick="func(&#39;Honors Awards&#39;)"><a href="./Honors Awards.html" class="scroll">Honors & Awards</a></li>-->
					<li id="MVPLab" onclick="func(&#39;MVP Lab&#39;)"><a href="./MVPLab.html" class="scroll">VIP Group</a></li>
                                        <!--<li id="Projects" onclick="func(&#39;Projects&#39;)"><a href="./Project.html" class="scroll">Projects</a></li>-->
					<!-- <li id="Art" onclick="func(&#39;Art&#39;)"><a href="http://www.icst.pku.edu.cn/struct/people/yangs/index.html#art" class="scroll">Art Gallery</a></li>	-->
					<li id="Profile-chinese" onclick="func(&#39;Profile-chinese&#39;)"><a href="./Profile-chinese.html" class="scroll">中文简介</a></li>
					<li id="Contact" onclick="func(&#39;Contact&#39;)"><a href="./Contact.html" class="scroll">Contact</a></li>
				</ul>
			</div>
			<div class="clear"> </div>
			<!---End-top-nav--->
	     </div>
	</div>
	
	<script> 
	var lastname = 'Me';
	function func(name){
		var div = document.getElementById(name); 
		div.className = 'active'; 
		div = document.getElementById(lastname); 
		div.className = ''; 
		lastname = name;
	}
	function coming_soon()
	{
		alert("Coming soon.");
	}
	</script> 
	
		<!---End-wrap--->
	<div class="content">
		<div class="grid3">
			<div class="grid3-content">
		<h3><b>Selected Publications and Patents:</b></h3>
	
                

	
	<!--COPYRIGHT: The copyright of the following materials belongs to corresponding publishers. 
They are provided only for research and educational use that does not conflict to the interests of the publishers.
-->
	  </ul>
  <hr />			
<!-- 			
<h4><b>Pre-print:</b></h4>
<ul class="graid3-ul">
<div style="text-align: justify; display: block; margin-right: auto;">
				

  </ul>
  <hr />-->
				

	<hr />	


				
<h4><b>2024:</b></h4>
		<ul class="graid3-ul">
  <div style="text-align: justify; display: block; margin-right: auto;">	
<li>Y. Zhang, Z. Li, H. Li and D. Tao, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10755138" target="_blank"><font color="#0000FF">"Prototype-Driven and Multi-Expert Integrated Multi-Modal MR Brain Tumor Image Segmentation"</font></a>, 
  <ud2>IEEE Transactions on Instrumentation and Measurement</ud2>, doi: 10.1109/TIM.2024.3500067.  
  <a href="https://github.com/Linzy0227/PDMINet." target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Huafeng and Fang, Jiaqi and Zhang, Yafei and Liu, Yu, 
  <a href="https://arxiv.org/abs/2411.12586" target="_blank"><font color="#0000FF">Infrared-Assisted Single-Stage Framework for Joint Restoration and Fusion of Visible and Infrared Images under Hazy Conditions</font></a>, 
  <ud2>arXiv preprint</ud2>, 2024.
</li>

<li>Yang, Zengyi and Zhang, Yafei and Li, Huafeng and Liu, Yu, 
  <a href="https://arxiv.org/abs/2411.09387" target="_blank"><font color="#0000FF">Instruction-Driven Fusion of Infrared-Visible Images: Tailoring for Diverse Downstream Tasks</font></a>, 
  <ud2>arXiv preprint</ud2>, 2024.
</li>

<li>Xie, Minghong and Wang, Mengzhao and Li, Huafeng and Zhang, Yafei and Tao, Dapeng and Yu, Zhengtao, 
  <a href="https://arxiv.org/abs/2410.23570" target="_blank"><font color="#0000FF">Phrase Decoupling Cross-Modal Hierarchical Matching and Progressive Position Correction for Visual Grounding</font></a>, 
  <ud2>arXiv preprint</ud2>, 2024.  
  <a href="https://github.com/X7J92/VGNet" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Fan and Zhou, Hang and Li, Huafeng and Zhang, Yafei and Yu, Zhengtao, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10701572" target="_blank"><font color="#0000FF">Person text-image matching via text-feature interpretability embedding and external attack node implantation</font></a>, 
  <ud2>IEEE Transactions on Emerging Topics in Computational Intelligence</ud2>, 2024.  
  <a href="https://github.com/lhf12278/SAA" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Huafeng and Zhang, Chen and Hu, Zhanxuan and Zhang, Yafei and Yu, Zhengtao, 
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608024002739" target="_blank"><font color="#0000FF">Interactive attack-defense for generalized person re-identification</font></a>, 
  <ud2>Neural Networks</ud2>, vol. 176, pp. 106349, 2024.  
  <a href="https://github.com/lhf12278/IAD." target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Zhang, Fan and Liu, Huiying and Wang, Jinjiang and Lyu, Jun and Cai, Qing and Li, Huafeng and Dong, Junyu and Zhang, David, 
  <a href="https://www.sciencedirect.com/science/article/pii/S0031320324001778" target="_blank"><font color="#0000FF">Cross co-teaching for semi-supervised medical image segmentation</font></a>, 
  <ud2>Pattern Recognition</ud2>, vol. 152, pp. 110426, 2024.  
  <a href="https://github.com/Fan-NWPU/CroCT" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Yu, Xiaoyan and Zhou, Shen and Li, Huafeng and Zhu, Liehuang, 
  <a href="https://arxiv.org/abs/2407.19139" target="_blank"><font color="#0000FF">Multi-Expert Adaptive Selection: Task-Balancing for All-in-One Image Restoration</font></a>, 
  <ud2>arXiv preprint</ud2>, 2024.  
  <a href="https://github.com/zhoushen1/MEASNet" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Xu, Kaixiong and Li, Huafeng and Chai, Yi and Guo, Maoyun, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10601528" target="_blank"><font color="#0000FF">Feature Adaptive Modulation and Prototype Learning for Domain Generalization Intelligent Fault Diagnosis</font></a>, 
  <ud2>IEEE Transactions on Industrial Informatics</ud2>, 2024.
</li>
<li>Hu, Qingsong and Li, Huafeng and Hu, Zhanxuan and Nie, Feiping, 
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253524000976" target="_blank"><font color="#0000FF">Diverse semantic information fusion for Unsupervised Person Re-Identification</font></a>, 
  <ud2>Information Fusion</ud2>, vol. 107, pp. 102319, 2024.  
  <a href="https://github.com/qingsonghu08/FuseDSI" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Gao, Yu and Zheng, Xutao and Li, Jinxing and Zong, Lijun and Yin, Hongpeng and Li, Huafeng and Lu, Guangming, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10531759/" target="_blank"><font color="#0000FF">Disentanglement Learning With Adaptive Centroid Alignment for Multiple Target Domains Fault Diagnosis</font></a>, 
  <ud2>IEEE Transactions on Industrial Informatics</ud2>, 2024.
</li>

<li>Zhang, Fan and Liu, Huiying and Duan, Xiaojun and Wang, Binglu and Cai, Qing and Li, Huafeng and Dong, Junyu and Zhang, David, 
  <a href="https://www.sciencedirect.com/science/article/pii/S0957417423032748" target="_blank"><font color="#0000FF">DSLSM: Dual-kernel-induced statistic level set model for image segmentation</font></a>, 
  <ud2>Expert Systems with Applications</ud2>, vol. 242, pp. 122772, 2024.
</li>

<li>Li, Zhiyuan and Zhang, Yafei and Li, Huafeng and Chai, Yi and Yang, Yushi, 
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1746809424000703" target="_blank"><font color="#0000FF">Deformation-aware and reconstruction-driven multimodal representation learning for brain tumor segmentation with missing modalities</font></a>, 
  <ud2>Biomedical Signal Processing and Control</ud2>, vol. 91, pp. 106012, 2024.  
  <a href="https://github.com/Linzy0227/SRMNet" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Huafeng and Liu, Junyu and Zhang, Yafei and Liu, Yu, 
  <a href="https://link.springer.com/article/10.1007/s11263-023-01948-x" target="_blank"><font color="#0000FF">A deep learning framework for infrared and visible image fusion without strict registration</font></a>, 
  <ud2>International Journal of Computer Vision</ud2>, vol. 132, no. 5, pp. 1625–1644, 2024.
</li>

<li>Li, Huafeng and Yang, Zhenmei and Zhang, Yafei and Tao, Dapeng and Yu, Zhengtao, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10465638" target="_blank"><font color="#0000FF">Single-Image HDR Reconstruction Assisted Ghost Suppression and Detail Preservation Network for Multi-Exposure HDR Imaging</font></a>, 
  <ud2>IEEE Transactions on Computational Imaging</ud2>, 2024.  
  <a href="https://github.com/lhf12278/SAMHDR" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Huafeng and Yuan, Ming and Li, Jinxing and Liu, Yu and Lu, Guangming and Xu, Yong and Yu, Zhengtao and Zhang, David, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10461111" target="_blank"><font color="#0000FF">Focus Affinity Perception and Super-Resolution Embedding for Multifocus Image Fusion</font></a>, 
  <ud2>IEEE Transactions on Neural Networks and Learning Systems</ud2>, 2024.
</li>

<li>Li, Huafeng and Hu, Qingsong and Hu, Zhanxuan, 
  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28092" target="_blank"><font color="#0000FF">Catalyst for Clustering-Based Unsupervised Object Re-identification: Feature Calibration</font></a>, 
  <ud2>Proceedings of the AAAI Conference on Artificial Intelligence</ud2>, vol. 38, no. 4, pp. 3091–3099, 2024.  
  <a href="https://github.com/lhf12278/FCM-ReID" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Zhang, Yafei and Yang, Xuji and Li, Huafeng and Xie, Minghong and Yu, Zhengtao, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10473165" target="_blank"><font color="#0000FF">DCPNet: A Dual-Task Collaborative Promotion Network for Pansharpening</font></a>, 
  <ud2>IEEE Transactions on Geoscience and Remote Sensing</ud2>, vol. 62, pp. 1–16, 2024.
</li>

<li>Wang, Hongbin and Chen, Rui and Shu, Zhenqiu and Zhang, Yafei and Li, Huafeng, 
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231223012365" target="_blank"><font color="#0000FF">Supervised adaptive similarity consistent latent representation hashing</font></a>, 
  <ud2>Neurocomputing</ud2>, vol. 570, pp. 127113, 2024.
</li>
<li>Li, Rui and Liu, Yishu and Li, Huafeng and Li, Jinxing and Lu, Guangming, 
  <a href="https://dl.acm.org/doi/abs/10.1145/3664647.3681211" target="_blank"><font color="#0000FF">Prototype-Guided Dual-Transformer Reasoning for Video Individual Counting</font></a>, 
  <ud2>Proceedings of the 32nd ACM International Conference on Multimedia</ud2>, pp. 10258–10267, 2024.
</li>

<li>万磊, 李华锋 and 张亚飞, 
  <a href="https://www.jcad.cn/cn/article/id/01ea269a-2c53-4c9e-8e24-dca9ce886115" target="_blank"><font color="#0000FF">多模态特征融合和自蒸馏的红外-可见光行人重识别</font></a>, 
  <ud2>计算机辅助设计与图形学学报</ud2>, 2024.
</li>

<li>毛彦嵋, 李华锋 and 张亚飞, 
  面向跨区域场景的无监督域自适应行人重识别 (网络首发), 
  <ud2>上海交通大学学报</ud2>, pp. 0, 2024.
</li>

<li>Zhang, Yafei and Zhou, Shen and Li, Huafeng, 
  <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Depth_Information_Assisted_Collaborative_Mutual_Promotion_Network_for_Single_Image_CVPR_2024_paper.html" target="_blank"><font color="#0000FF">Depth Information Assisted Collaborative Mutual Promotion Network for Single Image Dehazing</font></a>, 
  <ud2>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</ud2>, pp. 2846–2855, 2024.  
  <a href="https://github.com/zhoushen1/DCMPNet" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Chen, Liping and Xie, Siqiang and Lopes, António M and Li, Huafeng and Bao, Xinyuan and Zhang, Chaolong and Li, Penghua, 
  <a href="https://www.sciencedirect.com/science/article/pii/S0360544223029912" target="_blank"><font color="#0000FF">A new SOH estimation method for Lithium-ion batteries based on model-data-fusion</font></a>, 
  <ud2>Energy</ud2>, vol. 286, pp. 129597, 2024.
</li>
	  </ul>
  <hr />

				
<h4><b>2023:</b></h4>
		<ul class="graid3-ul">
  <div style="text-align: justify; display: block; margin-right: auto;">	

<li>Li, Huafeng, Dan Wang, Yuxin Huang, Yafei Zhang, and Zhengtao Yu, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10364841/" target="_blank"><font color="#0000FF">Generation and recombination for multifocus image fusion with free number of inputs</font></a>, 
  <ud2>IEEE Transactions on Circuits and Systems for Video Technology</ud2>, 2023.
  <a href="https://github.com/ChuhaoZhou99/SAADG_VVIReID" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Zhou, Chuhao, Jinxing Li, Huafeng Li, Guangming Lu, Yong Xu, and Min Zhang, 
  <a href="https://dl.acm.org/doi/abs/10.1145/3581783.3612479" target="_blank"><font color="#0000FF">Video-based visible-infrared person re-identification via style disturbance defense and dual interaction</font></a>, 
  <ud2>Proceedings of the 31st ACM International Conference on Multimedia</ud2>, pp. 46-55, 2023.
  <a href="https://github.com/ChuhaoZhou99/SAADG_VVIReID" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Kuang, Zhenyu, Chuchu He, Yue Huang, Xinghao Ding, and Huafeng Li, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10260258" target="_blank"><font color="#0000FF">Joint Image and Feature Levels Disentanglement for Generalizable Vehicle Re-identification</font></a>, 
  <ud2>IEEE Transactions on Intelligent Transportation Systems</ud2>, 2023.
</li>

<li>Li, Huafeng, Shedan Yang, Yafei Zhang, Dapeng Tao, and Zhengtao Yu, 
  <a href="https://arxiv.org/pdf/2308.11994" target="_blank"><font color="#0000FF">Progressive Feature Mining and External Knowledge-Assisted Text-Pedestrian Image Retrieval</font></a>, 
  <ud2>arXiv preprint</ud2>, 2023.
</li>

<li>Li, Huafeng, Yanmei Mao, Yafei Zhang, Guanqiu Qi, and Zhengtao Yu, 
  <a href="https://arxiv.org/abs/2307.06533" target="_blank"><font color="#0000FF">Domain-adaptive person re-identification without cross-camera paired samples</font></a>, 
  <ud2>arXiv preprint</ud2>, 2023.
</li>

<li>Li, Huafeng, Le Xu, Yafei Zhang, Dapeng Tao, and Zhengtao Yu, 
  <a href="https://arxiv.org/abs/2307.03903" target="_blank"><font color="#0000FF">Adversarial Self-Attack Defense and Spatial-Temporal Relation Mining for Visible-Infrared Video Person Re-Identification</font></a>, 
  <ud2>arXiv preprint</ud2>, 2023.
  <a href="https://github.com/lhf12278/xxx" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Huafeng, Junzhi Zhao, Jinxing Li, Zhengtao Yu, and Guangming Lu, 
  <a href="https://www.sciencedirect.com/science/article/pii/S1566253523000519" target="_blank"><font color="#0000FF">Feature dynamic alignment and refinement for infrared–visible image fusion: Translation robust fusion</font></a>, 
  <ud2>Information Fusion</ud2>, vol. 95, pp. 26-41, 2023.
  <a href="https://github.com/lhf12278/RFVIF" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Shuang, Fan Li, Jinxing Li, Huafeng Li, Bob Zhang, Dapeng Tao, and Xinbo Gao, 
  <a href="https://ieeexplore.ieee.org/abstract/document/10148098/" target="_blank"><font color="#0000FF">Logical relation inference and multiview information interaction for domain adaptation person re-identification</font></a>, 
  <ud2>IEEE Transactions on Neural Networks and Learning Systems</ud2>, 2023.
  <a href="https://jeit.ac.cn/article/doi/10.11999/JEIT220444?pageType=en" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Minghong, X. I. E., K. A. N. G. Bin, L. I. Huafeng, and Z. H. A. N. G. Yafei, 
  <a href="https://jeit.ac.cn/article/doi/10.11999/JEIT220444?pageType=en" target="_blank"><font color="#0000FF">Crowded Pedestrian Detection Method Combining Anchor Free and Anchor Base Algorithm</font></a>, 
  <ud2>电子与信息学报</ud2>, vol. 45, no. 5, pp. 1833-1841, 2023.
</li>

<li>Jiang, Bo, Jinxing Li, Huafeng Li, Ruxian Li, David Zhang, and Guangming Lu, 
  <a href="https://www.sciencedirect.com/science/article/pii/S1566253522002640" target="_blank"><font color="#0000FF">Enhanced frequency fusion network with dynamic hash attention for image denoising</font></a>, 
  <ud2>Information Fusion</ud2>, vol. 92, pp. 420-434, 2023.
</li>

<li>Tu, Yunbin, Chang Zhou, Junjun Guo, Huafeng Li, Shengxiang Gao, and Zhengtao Yu, 
  <a href="https://www.sciencedirect.com/science/article/pii/S0031320322006835" target="_blank"><font color="#0000FF">Relation-aware attention for video captioning via graph learning</font></a>, 
  <ud2>Pattern Recognition</ud2>, vol. 136, 2023.
</li>

<li>Wang, K., Lu, W., Liu, P., Yao, J., & Li, H., 
  <a href="https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/sil2.12182" target="_blank"><font color="#0000FF">Multi‐stage attention network for monaural speech enhancement</font></a>, 
  <ud2>IET Signal Processing</ud2>, vol. 17, no. 3, e12182, 2023.
  <a href="http://www.msp‐lab.cn:1436/msp/MSANet" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Li, Huafeng, Minghui Liu, Zhanxuan Hu, Feiping Nie, and Zhengtao Yu, 
  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10047982" target="_blank"><font color="#0000FF">Intermediary-Guided Bidirectional Spatial–Temporal Aggregation Network for Video-Based Visible-Infrared Person Re-Identification</font></a>, 
  <ud2>IEEE Transactions on Circuits and Systems for Video Technology</ud2>, vol. 33, no. 9, pp. 4962-4972, 2023.
  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10047982" target="_blank"><font color="#FF5151">[Code]</font></a>
</li>

<li>Liu, Minghui, Yafei Zhang, and Huafeng Li, 
  <a href="https://www.mdpi.com/2227-7390/11/3/654" target="_blank"><font color="#0000FF">Survey of Cross-Modal Person Re-Identification from a Mathematical Perspective</font></a>, 
  <ud2>Mathematics</ud2>, vol. 11, no. 3, pp. 654, 2023.
</li>

<li>Jirui, Gao, Li Huafeng, and Zhang Yafei, 
  Dual attention-guided detail and structure information fusion network for image dehazing, 
  <ud2>Acta Electronica Sinica</ud2>, vol. 51, no. 1, pp. 160-171, 2023.
</li>

	  
	  </ul>
  <hr />
			
			
			
			
	
<h4><b>2022:</b></h4>
		<ul class="graid3-ul">
  <div style="text-align: justify; display: block; margin-right: auto;">

<li> 石林波, 李华锋, 张亚飞, and 谢明鸿, "模态不变性特征学习和一致性细粒度信息挖掘的跨模态行人重识别", 模式识别与人工智能 (2022): 1.</li>

<li> Wang, Shujuan, Run Liu, Huafeng Li, Guanqiu Qi, and Zhengtao Yu, 
  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9933492" target="_blank"><font color="#0000FF">"Occluded person re-identification via defending against attacks from obstacles"</font></a>, 
  <ud2>IEEE Transactions on Information Forensics and Security</ud2>, vol. 18, pp. 147-161, 2022.</li>

<li> Zhang, Yafei, Yongzeng Wang, Huafeng Li, and Shuang Li, 
  <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548224" target="_blank"><font color="#0000FF">"Cross-compatible embedding and semantic consistent feature construction for sketch re-identification"</font></a>, 
  <ud2>Proceedings of the 30th ACM International Conference on Multimedia</ud2>, pp. 3347-3355, 2022. 
  <a href="https://github.com/lhf12278/CCSC" target="_blank"><font color="#FF5151">[Code]</font></a></li>

<li> Liu, Yu, Lei Wang, Huafeng Li, and Xun Chen, 
  <a href="https://www.sciencedirect.com/science/article/pii/S1566253522000513" target="_blank"><font color="#0000FF">"Multi-focus image fusion with deep residual learning and focus property detection"</font></a>, 
  <ud2>Information Fusion</ud2>, vol. 86, pp. 1-16, 2022.</li>

<li> Wang, Yiming, Guanqiu Qi, Shuang Li, Yi Chai, and Huafeng Li, 
  <a href="https://ieeexplore.ieee.org/abstract/document/9895288/" target="_blank"><font color="#0000FF">"Body part-level domain alignment for domain-adaptive person re-identification with transformer framework"</font></a>, 
  <ud2>IEEE Transactions on Information Forensics and Security</ud2>, vol. 17, pp. 3321-3334, 2022. 
  <a href="https://github.com/lhf12278/BPDA" target="_blank"><font color="#FF5151">[Code]</font></a></li>

<li> Li, Huafeng, Jirui Gao, Yafei Zhang, Minghong Xie, and Zhengtao Yu, 
  <a href="https://www.sciencedirect.com/science/article/pii/S0950705122006566" target="_blank"><font color="#0000FF">"Haze transfer and feature aggregation network for real-world single image dehazing"</font></a>, 
  <ud2>Knowledge-Based Systems</ud2>, vol. 251, pp. 109309, 2022. 
  <a href="https://github.com/lhf12278/HTFA-Net" target="_blank"><font color="#FF5151">[Code]</font></a></li>

<li> Li, Huafeng, Kaixiong Xu, Jinxing Li, and Zhengtao Yu, 
  <a href="https://www.sciencedirect.com/science/article/pii/S0950705122006591" target="_blank"><font color="#0000FF">"Dual-stream reciprocal disentanglement learning for domain adaptation person re-identification"</font></a>, 
  <ud2>Knowledge-Based Systems</ud2>, vol. 251, pp. 109315, 2022. 
  <a href="https://github.com/lhf12278/DRDL" target="_blank"><font color="#FF5151">[Code]</font></a></li>

<li> Li, Shuang, Fan Li, Kunpeng Wang, Guanqiu Qi, and Huafeng Li, 
  <a href="https://www.sciencedirect.com/science/article/pii/S1569190X22000594" target="_blank"><font color="#0000FF">"Mutual prediction learning and mixed viewpoints for unsupervised-domain adaptation person re-identification on blockchain"</font></a>, 
  <ud2>Simulation Modelling Practice and Theory</ud2>, vol. 119, pp. 102568, 2022. 
  <a href="https://github.com/lhf12278/MPL-MV" target="_blank"><font color="#FF5151">[Code]</font></a></li>

<li> Lin, Xinyu, Huafeng Li, and Qing Cai, 
  <a href="https://www.sciencedirect.com/science/article/pii/S092523122200741X" target="_blank"><font color="#0000FF">"Hierarchical complementary residual attention learning for defocus blur detection"</font></a>, 
  <ud2>Neurocomputing</ud2>, vol. 501, pp. 88-101, 2022.</li>

<li> Wang, Shujuan, Bochun Huang, Huafeng Li, Guanqiu Qi, Dapeng Tao, and Zhengtao Yu, 
  <a href="https://www.sciencedirect.com/science/article/pii/S0020025522005096" target="_blank"><font color="#0000FF">"Key point-aware occlusion suppression and semantic alignment for occluded person re-identification"</font></a>, 
  <ud2>Information Sciences</ud2>, vol. 606, pp. 669-687, 2022. 
  <a href="https://github.com/huangdaichui/occ_reid" target="_blank"><font color="#FF5151">[Code]</font></a></li>

<li> 李爽, 李华锋, and 李凡, 
  <a href="https://www.researching.cn/ArticlePdf/m00002/2022/59/10/1010010.pdf" target="_blank"><font color="#0000FF">"基于互预测学习的细粒度跨模态行人重识别"</font></a>, 
  <ud2>Laser & Optoelectronics Progress</ud2>, vol. 59, no. 10, pp. 1010010-1010010, 2022.</li>

<li> 肖万新, 李华锋, 张亚飞, 谢明鸿, and 李凡, 
  <a href="https://www.researching.cn/ArticlePdf/m00002/2022/59/6/0617029.pdf" target="_blank"><font color="#0000FF">"多尺度特征学习和边缘增强的医学图像融合"</font></a>, 
  <ud2>Laser & Optoelectronics Progress</ud2>, vol. 59, no. 6, pp. 0617029-0617029, 2022.</li>

<li> Cai, Qing, Jinxing Li, Huafeng Li, Yee-Hong Yang, Feng Wu, and David Zhang, 
  <a href="http://openaccess.thecvf.com/content/CVPR2022/html/Lin_Learning_Modal-Invariant_and_Temporal-Memory_for_Video-Based_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.html" target="_blank"><font color="#0000FF">"TDPN: Texture and detail-preserving network for single image super-resolution"</font></a>, 
  <ud2>IEEE Transactions on Image Processing</ud2>, vol. 31, pp. 2375-2389, 2022. 
  <a href="https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/cvi2.12068" target="_blank"><font color="#FF5151">[Code]</font></a></li>

<li> Wang, Meng, Zhengbing Guo, and Huafeng Li, 
  <a href="https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/cvi2.12068" target="_blank"><font color="#0000FF">"A dynamic routing CapsNet based on increment prototype clustering for overcoming catastrophic forgetting"</font></a>, 
  <ud2>IET Computer Vision</ud2>, vol. 16, no. 1, pp. 83-97, 2022.</li>

<li> Lin, Xinyu, Jinxing Li, Zeyu Ma, Huafeng Li, Shuang Li, Kaixiong Xu, Guangming Lu, and David Zhang, 
  <a href="http://openaccess.thecvf.com/content/CVPR2022/html/Lin_Learning_Modal-Invariant_and_Temporal-Memory_for_Video-Based_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.html" target="_blank"><font color="#0000FF">"Learning modal-invariant and temporal-memory for video-based visible-infrared person re-identification"</font></a>, 
  <ud2>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</ud2>, pp. 20973-20982, 2022.</li>
	 
	  </ul>
  <hr />
	
	
	
<h4><b>2021:</b></h4>
		<ul class="graid3-ul">
  <div style="text-align: justify; display: block; margin-right: auto;">
 
  
<li> 李玲莉, 谢明鸿, 李凡, 张亚飞, 李华锋, and 谭婷婷, 
  <a href="http://qks.cqu.edu.cn/cqdxzren/article/abstract/20211108?st=article_issue" target="_blank">
    <font color="#0000FF">Unsupervised domain adaptive person re-identification guided by low-rank priori</font>
  </a>, 
  <ud2>重庆大学学报</ud2>, vol. 44, no. 11, pp. 57-70, 2021.
</li>

<li> Li, Huafeng, Neng Dong, Zhengtao Yu, Dapeng Tao, and Guanqiu Qi, 
  <a href="https://ieeexplore.ieee.org/abstract/document/9495801/" target="_blank">
    <font color="#0000FF">Triple adversarial learning and multi-view imaginative reasoning for unsupervised domain adaptation person re-identification</font>
  </a>, 
  <ud2>IEEE Transactions on Circuits and Systems for Video Technology</ud2>, vol. 32, no. 5, pp. 2814-2830, 2021.
  <a href="https://github.com/lhf12278/TALM-IRM" target="_blank">
    <font color="#FF5151">[Code]</font>
  </a>
</li>

<li> Pang, Jian, Dacheng Zhang, Huafeng Li, Weifeng Liu, and Zhengtao Yu, 
  <a href="https://ieeexplore.ieee.org/abstract/document/9428462/" target="_blank">
    <font color="#0000FF">Hazy re-ID: An interference suppression model for domain adaptation person re-identification under inclement weather condition</font>
  </a>, 
  <ud2>2021 IEEE International Conference on Multimedia and Expo (ICME)</ud2>, pp. 1-6, 2021.
  <a href="https://github.com/pangjian123/ISM-ReID" target="_blank">
    <font color="#FF5151">[Code]</font>
  </a>
</li>

<li> Li, Huafeng, Jian Pang, Dapeng Tao, and Zhengtao Yu, 
  <a href="https://www.sciencedirect.com/science/article/pii/S0020025521000359" target="_blank">
    <font color="#0000FF">Cross adversarial consistency self-prediction learning for unsupervised domain adaptation person re-identification</font>
  </a>, 
  <ud2>Information Sciences</ud2>, vol. 559, pp. 46-60, 2021.
  <a href="https://github.com/PangJian123/CAC-CSP" target="_blank">
    <font color="#FF5151">[Code]</font>
  </a>
</li>

<li> Li, Huafeng, Yueliang Cen, Yu Liu, Xun Chen, and Zhengtao Yu, 
  <a href="https://ieeexplore.ieee.org/abstract/document/9394791/" target="_blank">
    <font color="#0000FF">Different input resolutions and arbitrary output resolution: A meta learning-based deep framework for infrared and visible image fusion</font>
  </a>, 
  <ud2>IEEE Transactions on Image Processing</ud2>, vol. 30, pp. 4070-4083, 2021.
  <a href="https://github.com/yuliu316316/MetaLearning-Fusion" target="_blank">
    <font color="#FF5151">[Code]</font>
  </a>
</li>

<li> Li, Huafeng, Moyuan Yang, and Zhengtao Yu, 
  <a href="https://www.sciencedirect.com/science/article/pii/S0925231220314314" target="_blank">
    <font color="#0000FF">Joint image fusion and super-resolution for enhanced visualization via semi-coupled discriminative dictionary learning and advantage embedding</font>
  </a>, 
  <ud2>Neurocomputing</ud2>, vol. 422, pp. 62-84, 2021.
</li>
	 
	  </ul>
  <hr />
	
	
<h4><b>2020:</b></h4>
		<ul class="graid3-ul">
<div style="text-align: justify; display: block; margin-right: auto;">  



  
	</ul>
			<hr />
				
<h4><b>2019:</b></h4>
<ul class="graid3-ul">
  <div style="text-align: justify; display: block; margin-right: auto;">

 	  
	  
	  
</ul>
	<hr />
  
<h4><b>2018:</b></h4>
		<ul class="graid3-ul">
  <div style="text-align: justify; display: block; margin-right: auto;">


  </ul>
  <hr />
			
<h4><b>2017:</b></h4>
		<ul class="graid3-ul">
<div style="text-align: justify; display: block; margin-right: auto;">  


  </ul>
			<hr />
			
<h4><b>2016:</b></h4>
		<ul class="graid3-ul">
<div style="text-align: justify; display: block; margin-right: auto;">
	

</ul>
			<hr />
<!--
<h4><b>2015:</b></h4>
		<ul class="graid3-ul">
 <div style="text-align: justify; display: block; margin-right: auto;">
	 
<li> Ping Han, <strong>Runmin Cong</strong>, and Zaiji Zhang, 
  <font color="#0000FF">Change detection algorithm of polarimetric SAR image based on polarization state extracting</font>,
  <ud2>Systems Engineering and Electronics</ud2>, vol. 37, no. 7, pp. 1526-1530, 2015. (in Chinese, EI)<br></li>
  </ul>
				<hr />
-->
			
<h4><b>授权中国发明专利:</b></h4>
<ul class="graid3-ul">
<div style="text-align: justify; display: block; margin-right: auto;">
	 
<li>一种立体视觉显著性检测方法，专利号：ZL 201610244589.9，申请日：2016.04.19，授权公告日：2018.08.31</li>
<li>一种RGB-D图像显著性目标检测方法，专利号：ZL 202110872457.1，申请日：2021.07.30，授权公告日：2023.07.28</li>
<li>一种RGB-D图像显著性目标检测方法，专利号：ZL 202010199264.X，申请日：2020.03.20，授权公告日：2023.08.30</li>
<li>一种图间显著性检测方法，专利号：ZL 201710942099.0，申请日：2017.10.11，授权公告日：2021.04.16</li>
<li>一种深度图可靠性评价测度方法，专利号：ZL 201610242241.6，申请日：2016.04.19，授权公告日：2018.08.10</li>	 
<li>一种迭代协同显著性检测方法，专利号：ZL 201711064083.0，申请日：2017.11.02，授权公告日：2021.06.04</li>
<li>一种协同显著性检测方法，专利号：ZL 201710942783.9，申请日：2017.10.11，授权公告日：2021.06.04</li>
<li>一种深度形状先验提取方法，专利号：ZL 201711065005.2，申请日：2017.11.02，授权公告日：2021.04.30</li>
<li>一种 RGBD 图像协同显著性检测方法，专利号：ZL 201810879724.6，申请日：2018.08.03，授权公告日：2021.09.17</li>
<li>一种RGB显著性到RGBD显著性的转换方法，专利号：ZL 201910375809.5，申请日：2019.05.07，授权公告日：2023.04.18</li>	
<li>一种视频显著性检测方法，专利号：ZL 201910266112.4，申请日：2019.04.03，授权公告日：2023.02.07</li>	
<li>一种立体图像重定向方法，专利号：ZL 201610874827.4，申请日：2016.09.30，授权公告日：2019.12.06</li>
<li>一种深度视频快速帧内编码方法，专利号：ZL 201810317701.6，申请日：2018.04.10，授权公告日：2021.04.30</li>
<li>一种联合场景和运动多特征的视频行为聚类方法，专利号：ZL 201810962264.3，申请日：2018.08.22，授权公告日：2021.06.04</li>
<li>深度图超分辨率重建方法，专利号：ZL 201610727602.6，申请日：2016.08.25，授权公告日：2019.10.18</li>	
<li>一种2D转3D深度估计方法，专利号：ZL 201610780883.1，申请日：2016.08.31，授权公告日：2019.06.04</li>	 	 
<li>一种立体图像匹配图计算方法，专利号：ZL 201610780786.2，申请日：2016.08.31，授权公告日：2019.05.31</li>	
<li>一种基于最优化颜色修正和回归模型的水下图像复原方法，专利号：ZL 201610606187.9，申请日：2016.07.25，授权公告日：2019.03.29</li>  
<li>一种屏幕内容与自然内容划分及快速编码方法，专利号：ZL 201611031480.3，申请日：2016.11.18，授权公告日：2019.01.29</li>
<li>一种基于虚拟视点绘制质量的深度图上采样方法，专利号：ZL 201610751851.9，申请日：2016.08.27，授权公告日：2019.08.02</li>	
<li>一种基于协同注意力的草图图像检索方法，专利号：ZL 201910746351.X，申请日：2019.08.13，授权公告日：2022.11.15</li>	
<li>一种基于半异构联合嵌入网络的草图图像检索方法，专利号：ZL 201910746354.3 申请日：2019.08.13，授权公告日：2022.12.02</li>	
	 
	<!-- 
<li><strong>丛润民</strong>，雷建军，侯春萍，李重仪，贺小旭，段金辉. 一种立体视觉显著性检测方法，专利号：ZL 201610244589.9，申请日：2016.04.20，授权公告日：2018.08.31
</li>

<li>雷建军，<strong>丛润民</strong>，侯春萍，段金辉，李东阳. 一种深度图可靠性评价测度，专利号：ZL 201610242241.6，申请日：2016.04.20，授权公告日：2018.08.10
 </li>	 

<li>雷建军，<strong>丛润民</strong>，侯春萍，张三义，陈越，郭琰. 一种迭代协同显著性检测方法，专利号：ZL 201711064083.0，申请日：2017.11.02，授权公告日：2021.06.04</li>
<li>雷建军，<strong>丛润民</strong>，侯春萍，张静，范晓婷，彭勃. 一种协同显著性检测方法，专利号：ZL 201710942783.9，申请日：2017.10.11，授权公告日：2021.06.04</li>
<li>雷建军，<strong>丛润民</strong>，侯春萍，李欣欣，韩梦芯，罗晓维. 一种深度形状先验提取方法，专利号：ZL 201711065005.2，申请日：2017.11.02，授权公告日：2021.04.30</li>
<li>雷建军，张凯明，孙振燕，彭勃，<strong>丛润民</strong>，张曼华，徐遥令. 一种深度视频快速帧内编码方法，专利号：ZL 201810317701.6，申请日：2018.04.10，授权公告日：2021.04.30</li>
<li>雷建军，彭勃，郑泽勋，贾亚龙，<strong>丛润民</strong>，张静. 一种联合场景和运动多特征的视频行为聚类方法，申请号：201810962264.3，申请日：2018.08.22，授权公告日：2021.06.04</li>


<li>郭继昌，李重仪，<strong>丛润民</strong>，郭春乐，顾翔元.一种基于最优化颜色修正和回归模型的水下图像复原方法，专利号：ZL 201610606187.9，申请日：2016.07.25，授权公告日：2019.03.29
 </li> 

<li>雷建军，吴敏，侯春萍，<strong>丛润民</strong>，李乐乐，郭琰. 一种立体图像重定向方法，专利号：ZL 201610874827.4，申请日：2016.09.30，授权公告日：2019.12.06
 </li>
	 
<li>雷建军，李乐乐，侯春萍，<strong>丛润民</strong>，张凝，吴敏. 一种基于虚拟视点绘制质量的深度图上采样方法，专利号：ZL 201610751851.9，申请日：2016.08.27，授权公告日：2019.08.02
 </li>	 
	 
<li>雷建军，李乐乐，侯春萍，吴敏，<strong>丛润民</strong>，倪敏. 深度图超分辨率重建方法，专利号：ZL 201610727602.6，申请日：2016.08.25，授权公告日：2019.10.18
</li>	
	 
<li>吴敏，雷建军，侯春萍，李乐乐，<strong>丛润民</strong>，梅旭光. 一种立体图像匹配图计算方法，专利号：ZL 201610780786.2，申请日：2016.08.31，授权公告日：2019.05.31
</li>	
	 
<li>雷建军，李东阳，侯春萍，孙振燕，<strong>丛润民</strong>，彭勃. 一种屏幕内容与自然内容划分及快速编码方法，专利号：ZL 201611031480.3，申请日：2016.11.18，授权公告日：2019.01.29
   </li>
	 
<li>雷建军，张凝，侯春萍，张翠翠，郑凯夫，<strong>丛润民</strong>. 一种2D转3D深度估计方法，专利号：ZL 201610780883.1，申请日：2016.08.31，授权公告日：2019.06.04
 </li>	 	 
	--> 
  </ul>	
	<hr />
			
<ul class="graid3-ul">
        <div style="text-align: justify; display: block; margin-right: auto;">
	Here are the Impact Factors (IF) of selected journals of my publications. <br>
        - IEEE Transactions on Cybernetics (TCyb): 19.118 <br>
	- IEEE Transactions on Neural Networks and Learning Systems (TNNLS): 14.255<br>
	- IEEE Transactions on Industrial Informatics (TII): 11.648<br>
	- IEEE Transactions on Image Processing (TIP): 11.041 <br>
	- IEEE Transactions on Intelligent Transportation Systems (TITS): 9.551  <br>
	- IEEE Transactions on Multimedia (TMM): 8.182 <br> 
	- IEEE Transactions on Geoscience and Remote Sensing (TGRS): 8.125 <br>
	- IEEE Transactions on Circuits and Systems for Video Technology (TCSVT): 5.859 <br>
	- IEEE Transactions on Automation Science and Engineering (TASE): 5.6 <br>
	- IEEE Transactions on Instrumentation and Measurement (TIM): 5.332 <br>
	- IEEE Transactions on Computational Imaging (TCI): 4.708 <br>
	- IEEE Transactions on Consumer Electronics (TCE): 4.414 <br>
	- IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI): 4.851 <br>
	- IEEE Journal of Biomedical and Health Informatics (JBHI): 7.021<br>
	- SCIENCE CHINA Information Sciences (SCIS): 7.275<br>
	- ACM Transactions on Multimedia Computing Communications and Applications (TOMM): 4.094<br>
	- Information Sciences: 8.233 <br>
	- Neurocomputing: 5.779 <br>
	- Pattern Recognition Letters (PRL): 4.757 <br>
	- IEEE Signal Processing Letters (SPL): 3.201 <br>
	- International Journal of Remote Sensing (IJRS): 3.531	 <br>
	- Signal Processing: Image Communication (SPIC): 3.453 <br>
	- Multimedia Tools and Applications (MTAP): 2.577 <br>
	- Journal of Electronic Imaging (JEI): 0.829<br>
	
	
			
			
	</div>			
		</div>	
	</div>
	
		<script type="text/javascript" src="./files/jquery.min.js.下载"></script>
		<script type="text/javascript" src="./files/bootstrap.js.下载"></script>
		<script type="text/javascript" src="./files/jquery.banner.js.下载"></script>
		<script type="text/javascript" src="./files/jquery.prettyPhoto.js.下载"></script>		
		<script type="text/javascript" src="./files/jquery.isotope.js.下载"></script>	
		<script type="text/javascript" src="./files/main.js.下载"></script>				
	


</body></html>
